{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "import os\n",
    "\n",
    "# CQT Configuration \n",
    "hop_length_sec = 0.01               # 10 ms\n",
    "fmin = librosa.note_to_hz('A0')     # Start at A0 (piano)\n",
    "bins_per_octave = 36                # 3 bins per semitone\n",
    "n_bins = 267                        # Covers A0 to C8\n",
    "sr = 22050\n",
    "hop_length = int(hop_length_sec * sr)\n",
    "\n",
    "def plot_cqt_with_pianoroll(audio_path, midi_path):\n",
    "    cqt_list = []\n",
    "    y, _ = librosa.load(audio_path, sr=sr)\n",
    "\n",
    "    C = librosa.cqt(\n",
    "        y, sr=sr,\n",
    "        hop_length=hop_length,\n",
    "        fmin=fmin,\n",
    "        n_bins=n_bins,\n",
    "        bins_per_octave=bins_per_octave\n",
    "    )\n",
    "    C_dB = librosa.amplitude_to_db(np.abs(C), ref=np.max)\n",
    "\n",
    "    # Load MIDI and get piano roll\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
    "    fs_pianoroll = sr / hop_length  # Frame rate to match CQT\n",
    "    piano_roll = midi_data.get_piano_roll(fs=fs_pianoroll)\n",
    "\n",
    "    # Align time axes\n",
    "    n_frames = min(C_dB.shape[1], piano_roll.shape[1])\n",
    "    return C_dB[:, :n_frames], piano_roll[:, :n_frames]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_path = r'note_silence\\audio'\n",
    "# midi_path = r'note_silence\\midi'\n",
    "\n",
    "audio_path = r'note_silence_combined'\n",
    "midi_path = r'note_silence_combined'\n",
    "num_sample =5\n",
    "cqt_list = []\n",
    "piano_list = []\n",
    "# dura = '0_0312'\n",
    "for k in range(1):\n",
    "    for i in range(num_sample):\n",
    "        if i:\n",
    "            audio = os.path.join(audio_path, 'C4_durations_combined.mp3')\n",
    "            midi = os.path.join(midi_path, 'C4_durations_combined.mid')\n",
    "            cqt , piano = plot_cqt_with_pianoroll(audio, midi)\n",
    "            cqt_list.append(cqt)\n",
    "            piano_list.append(piano)\n",
    "cqt_concat = np.concatenate(cqt_list, axis=1)  # along time axis\n",
    "piano_concat = np.concatenate(piano_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 16028)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cqt_concat.shape\n",
    "piano_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration_sec = piano_concat.shape[1] * hop_length / sr\n",
    "\n",
    "# # Plot setup\n",
    "# fig, axs = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "# # Plot CQT \n",
    "# librosa.display.specshow(\n",
    "#     cqt_concat[:,:],\n",
    "#     sr=sr,\n",
    "#     hop_length=hop_length,\n",
    "#     x_axis='s',                  \n",
    "#     y_axis='cqt_note',\n",
    "#     fmin=fmin,\n",
    "#     bins_per_octave=bins_per_octave,\n",
    "#     cmap='magma',\n",
    "#     ax=axs[0]\n",
    "# )\n",
    "# axs[0].set_title(\"CQT Spectrogram\")\n",
    "# axs[0].label_outer()  \n",
    "\n",
    "# # Plot Piano Roll\n",
    "# pitch_min = 21\n",
    "# pitch_max = 108\n",
    "\n",
    "# axs[1].imshow(\n",
    "#     piano_concat[pitch_min:pitch_max+1, :],\n",
    "#     aspect='auto',\n",
    "#     origin='lower',\n",
    "#     cmap='gray_r',\n",
    "#     interpolation='nearest',\n",
    "#     extent=[0, duration_sec, pitch_min, pitch_max]\n",
    "# )\n",
    "\n",
    "# axs[1].set_xlabel('Time (seconds)')\n",
    "# axs[1].set_ylabel('MIDI Pitch (Note Names)')\n",
    "# axs[1].set_title('Piano Roll')\n",
    "# axs[1].set_ylim(pitch_min, pitch_max)\n",
    "\n",
    "# # Label only natural C notes\n",
    "# c_notes = [n for n in range(pitch_min, pitch_max+1)\n",
    "#            if pretty_midi.note_number_to_name(n).startswith('C') and '#' not in pretty_midi.note_number_to_name(n)]\n",
    "# axs[1].set_yticks(c_notes)\n",
    "# axs[1].set_yticklabels([pretty_midi.note_number_to_name(n) for n in c_notes])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_windows(cqt, window_size=9, stride=1):\n",
    "    pad = window_size // 2\n",
    "    cqt_padded = np.pad(cqt, ((0, 0), (pad, pad)), mode='edge')\n",
    "    num_time_bins = cqt.shape[1]\n",
    "\n",
    "    windows = np.array([\n",
    "        cqt_padded[:, i:i + window_size]\n",
    "        for i in range(0, num_time_bins, stride)\n",
    "    ])\n",
    "    \n",
    "    return windows[..., np.newaxis] \n",
    "\n",
    "def create_sliding_windows_midi(midi, window_size=9, stride=1):\n",
    "    pad = window_size // 2\n",
    "    midi_padded = np.pad(midi, ((0, 0), (pad, pad)), mode='constant', constant_values=0)\n",
    "    num_time_bins = midi.shape[1]\n",
    "\n",
    "    windows = np.array([\n",
    "        midi_padded[:, i:i + window_size]\n",
    "        for i in range(0, num_time_bins, stride)\n",
    "    ])\n",
    "    \n",
    "    return windows, len(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sliding Window Output Shape: (16028, 267, 9, 1)\n",
      "Sliding Window MIDI Output Shape: (16028, 128, 9)\n"
     ]
    }
   ],
   "source": [
    "X_input = create_sliding_windows(cqt_concat, window_size=9, stride=1)  # (num_windows, 267, 9, 1)\n",
    "print(\"Sliding Window Output Shape:\", X_input.shape)\n",
    "\n",
    "Y_output, num_windows_midi = create_sliding_windows_midi(piano_concat, window_size=9, stride=1)\n",
    "print(\"Sliding Window MIDI Output Shape:\", Y_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0., 100., 100., 100., 100., 100.])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Y_output[0][60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain :  (16028, 267, 9, 1)\n",
      "out :  (16028, 128, 9)\n",
      "Ytrain :  (16028, 128)\n"
     ]
    }
   ],
   "source": [
    "Y_output_flattened = np.mean(Y_output, axis=2) >= 45  # Shape: (n, 128)\n",
    "# print(Y_output_flattened)\n",
    "print(\"Xtrain : \",X_input.shape)\n",
    "print(\"out : \",Y_output.shape)\n",
    "print(\"Ytrain : \",Y_output_flattened.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librosa.display.specshow(cqt_concat[:, :1000], sr=sr, hop_length=hop_length,\n",
    "#                             x_axis='time', y_axis='cqt_note',\n",
    "#                             fmin=fmin, bins_per_octave=bins_per_octave,\n",
    "#                             cmap='magma')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (Conv2D)              (None, 252, 8, 10)        330       \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 126, 4, 10)        0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 116, 2, 20)        6620      \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 58, 1, 20)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1160)              0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 256)               297216    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 128)               32896     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 337,062\n",
      "Trainable params: 337,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "num_classes = 128\n",
    "import datetime\n",
    "\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Create the callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(10, (16, 2), activation='relu', padding='valid', input_shape=(267, 9, 1), name=\"conv1\"),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), name=\"pool1\"),\n",
    "    tf.keras.layers.Conv2D(20, (11, 3), activation='relu', padding='valid', name=\"conv2\"),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), name=\"pool2\"),\n",
    "    tf.keras.layers.Flatten(name=\"flatten\"),\n",
    "    tf.keras.layers.Dense(256, activation='relu', name=\"fc1\"),\n",
    "    tf.keras.layers.Dropout(0.5, name=\"dropout\"),\n",
    "    tf.keras.layers.Dense(num_classes, activation='sigmoid', name=\"fc2\")\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 5.4756e-04 - accuracy: 0.5005 - val_loss: 3.9854e-04 - val_accuracy: 0.5003\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 5.1383e-04 - accuracy: 0.5004 - val_loss: 8.7131e-04 - val_accuracy: 0.5003\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 5.8332e-04 - accuracy: 0.5005 - val_loss: 3.3834e-04 - val_accuracy: 0.5003\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 4.4064e-04 - accuracy: 0.5005 - val_loss: 3.3439e-04 - val_accuracy: 0.5003\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 4.8961e-04 - accuracy: 0.5004 - val_loss: 2.8811e-04 - val_accuracy: 0.5003\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 4.2451e-04 - accuracy: 0.5005 - val_loss: 2.6555e-04 - val_accuracy: 0.5003\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 3.8180e-04 - accuracy: 0.5005 - val_loss: 2.6815e-04 - val_accuracy: 0.5003\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 3.5957e-04 - accuracy: 0.5003 - val_loss: 2.5966e-04 - val_accuracy: 0.5003\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 3.9736e-04 - accuracy: 0.5005 - val_loss: 3.2194e-04 - val_accuracy: 0.5003\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 3.4095e-04 - accuracy: 0.5005 - val_loss: 2.4227e-04 - val_accuracy: 0.5003\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 3.0352e-04 - accuracy: 0.5004 - val_loss: 2.1161e-04 - val_accuracy: 0.5003\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 3.1435e-04 - accuracy: 0.5003 - val_loss: 2.8954e-04 - val_accuracy: 0.5003\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 3.5920e-04 - accuracy: 0.5006 - val_loss: 2.1656e-04 - val_accuracy: 0.5003\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 2.8265e-04 - accuracy: 0.5005 - val_loss: 1.8503e-04 - val_accuracy: 0.5003\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 5s 89ms/step - loss: 2.5468e-04 - accuracy: 0.5004 - val_loss: 1.8711e-04 - val_accuracy: 0.5003\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 5s 89ms/step - loss: 2.5767e-04 - accuracy: 0.5005 - val_loss: 1.6870e-04 - val_accuracy: 0.5003\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 2.3243e-04 - accuracy: 0.5005 - val_loss: 1.9825e-04 - val_accuracy: 0.5003\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2.3001e-04 - accuracy: 0.5005 - val_loss: 1.9324e-04 - val_accuracy: 0.5003\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 2.4691e-04 - accuracy: 0.5006 - val_loss: 2.7285e-04 - val_accuracy: 0.5003\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 2.4468e-04 - accuracy: 0.5004 - val_loss: 1.4504e-04 - val_accuracy: 0.5003\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 1.9940e-04 - accuracy: 0.5004 - val_loss: 1.3530e-04 - val_accuracy: 0.5003\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 1.8670e-04 - accuracy: 0.5005 - val_loss: 1.3028e-04 - val_accuracy: 0.5003\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 2.4618e-04 - accuracy: 0.5004 - val_loss: 1.2365e-04 - val_accuracy: 0.5003\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 2.0090e-04 - accuracy: 0.5005 - val_loss: 1.5796e-04 - val_accuracy: 0.5003\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 1.7262e-04 - accuracy: 0.5004 - val_loss: 1.1002e-04 - val_accuracy: 0.5003\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 1.6830e-04 - accuracy: 0.5005 - val_loss: 1.1033e-04 - val_accuracy: 0.5003\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 2.1232e-04 - accuracy: 0.5005 - val_loss: 1.2926e-04 - val_accuracy: 0.5003\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 1.6045e-04 - accuracy: 0.5004 - val_loss: 1.8220e-04 - val_accuracy: 0.5003\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 1.6720e-04 - accuracy: 0.5005 - val_loss: 9.2983e-05 - val_accuracy: 0.5003\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 1.2932e-04 - accuracy: 0.5004 - val_loss: 1.0582e-04 - val_accuracy: 0.5003\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 1.6015e-04 - accuracy: 0.5004 - val_loss: 9.7815e-05 - val_accuracy: 0.5003\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 1.8547e-04 - accuracy: 0.5004 - val_loss: 9.4328e-05 - val_accuracy: 0.5003\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 1.4822e-04 - accuracy: 0.5004 - val_loss: 2.7597e-04 - val_accuracy: 0.5003\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 1.8501e-04 - accuracy: 0.5004 - val_loss: 1.5468e-04 - val_accuracy: 0.5003\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 1.2910e-04 - accuracy: 0.5005 - val_loss: 8.0791e-05 - val_accuracy: 0.5003\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 1.5464e-04 - accuracy: 0.5004 - val_loss: 8.0449e-05 - val_accuracy: 0.5003\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 1.2509e-04 - accuracy: 0.5004 - val_loss: 1.1530e-04 - val_accuracy: 0.5003\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 1.2201e-04 - accuracy: 0.5004 - val_loss: 6.5695e-05 - val_accuracy: 0.5003\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 1.0229e-04 - accuracy: 0.5004 - val_loss: 8.9978e-05 - val_accuracy: 0.5003\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 1.6523e-04 - accuracy: 0.5004 - val_loss: 7.5994e-05 - val_accuracy: 0.5003\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 1.0745e-04 - accuracy: 0.5004 - val_loss: 1.2811e-04 - val_accuracy: 0.5003\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 1.2860e-04 - accuracy: 0.5004 - val_loss: 6.3655e-05 - val_accuracy: 0.5003\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 9.5449e-05 - accuracy: 0.5004 - val_loss: 5.3697e-05 - val_accuracy: 0.5003\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 9.4422e-05 - accuracy: 0.5004 - val_loss: 7.4539e-05 - val_accuracy: 0.5003\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 9.7496e-05 - accuracy: 0.5004 - val_loss: 6.7459e-05 - val_accuracy: 0.5003\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 8.5264e-05 - accuracy: 0.5005 - val_loss: 4.2001e-05 - val_accuracy: 0.5003\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 8.2477e-05 - accuracy: 0.5004 - val_loss: 7.5761e-05 - val_accuracy: 0.5003\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 8.7758e-05 - accuracy: 0.5004 - val_loss: 4.5771e-05 - val_accuracy: 0.5003\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 8.0072e-05 - accuracy: 0.5004 - val_loss: 5.9885e-05 - val_accuracy: 0.5003\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 2.2927e-04 - accuracy: 0.5004 - val_loss: 1.1700e-04 - val_accuracy: 0.5003\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 9.9074e-05 - accuracy: 0.5004 - val_loss: 4.0253e-05 - val_accuracy: 0.5003\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 7.3394e-05 - accuracy: 0.5005 - val_loss: 3.6511e-05 - val_accuracy: 0.5003\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 9.2482e-05 - accuracy: 0.5004 - val_loss: 5.1210e-05 - val_accuracy: 0.5003\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 5.6806e-05 - accuracy: 0.5005 - val_loss: 3.2759e-05 - val_accuracy: 0.5003\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 6.0026e-05 - accuracy: 0.5004 - val_loss: 3.2780e-05 - val_accuracy: 0.5003\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 6.0481e-05 - accuracy: 0.5004 - val_loss: 4.0478e-05 - val_accuracy: 0.5003\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 6.7683e-05 - accuracy: 0.5004 - val_loss: 3.3736e-05 - val_accuracy: 0.5003\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 6.4714e-05 - accuracy: 0.5004 - val_loss: 6.6364e-05 - val_accuracy: 0.5003\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 7.2667e-05 - accuracy: 0.5004 - val_loss: 2.5826e-05 - val_accuracy: 0.5003\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 5s 100ms/step - loss: 4.9523e-05 - accuracy: 0.5005 - val_loss: 2.6786e-05 - val_accuracy: 0.5003\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 7.1703e-05 - accuracy: 0.5004 - val_loss: 2.5005e-05 - val_accuracy: 0.5003\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 7.5826e-05 - accuracy: 0.5004 - val_loss: 2.3770e-05 - val_accuracy: 0.5003\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 5.6476e-05 - accuracy: 0.5005 - val_loss: 2.1702e-05 - val_accuracy: 0.5003\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 4.6507e-05 - accuracy: 0.5004 - val_loss: 1.9300e-05 - val_accuracy: 0.5003\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 4.6593e-05 - accuracy: 0.5004 - val_loss: 8.3219e-05 - val_accuracy: 0.5003\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 7.0656e-05 - accuracy: 0.5004 - val_loss: 2.5748e-05 - val_accuracy: 0.5003\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 5.3406e-05 - accuracy: 0.5005 - val_loss: 2.1922e-05 - val_accuracy: 0.5003\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 3.5642e-05 - accuracy: 0.5004 - val_loss: 1.8804e-05 - val_accuracy: 0.5003\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 4.4064e-05 - accuracy: 0.5004 - val_loss: 3.2410e-05 - val_accuracy: 0.5003\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 3.5459e-05 - accuracy: 0.5004 - val_loss: 1.9524e-05 - val_accuracy: 0.5003\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 4.6352e-05 - accuracy: 0.5004 - val_loss: 1.7280e-05 - val_accuracy: 0.5003\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 4.5400e-05 - accuracy: 0.5004 - val_loss: 1.9461e-05 - val_accuracy: 0.5003\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 4.0351e-05 - accuracy: 0.5004 - val_loss: 1.3699e-04 - val_accuracy: 0.5003\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 9.4838e-05 - accuracy: 0.5005 - val_loss: 3.8703e-05 - val_accuracy: 0.5003\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 6.8538e-05 - accuracy: 0.5004 - val_loss: 1.4815e-04 - val_accuracy: 0.5003\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 6.1890e-05 - accuracy: 0.5004 - val_loss: 4.2184e-05 - val_accuracy: 0.5003\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 4.4879e-04 - accuracy: 0.5003 - val_loss: 9.6298e-05 - val_accuracy: 0.5003\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 1.0692e-04 - accuracy: 0.5004 - val_loss: 5.5520e-05 - val_accuracy: 0.5003\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 7.1135e-05 - accuracy: 0.5004 - val_loss: 4.0199e-05 - val_accuracy: 0.5003\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 4.7342e-05 - accuracy: 0.5004 - val_loss: 2.6464e-05 - val_accuracy: 0.5003\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 7.2637e-05 - accuracy: 0.5004 - val_loss: 3.0881e-05 - val_accuracy: 0.5003\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 1.1990e-04 - accuracy: 0.5005 - val_loss: 1.0960e-04 - val_accuracy: 0.5003\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 5.9486e-05 - accuracy: 0.5004 - val_loss: 7.0745e-05 - val_accuracy: 0.5003\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 4.1164e-05 - accuracy: 0.5004 - val_loss: 3.9023e-05 - val_accuracy: 0.5003\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 7.5736e-05 - accuracy: 0.5004 - val_loss: 5.7355e-05 - val_accuracy: 0.5003\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 6.9095e-05 - accuracy: 0.5004 - val_loss: 1.7869e-05 - val_accuracy: 0.5003\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 3.6816e-05 - accuracy: 0.5004 - val_loss: 3.6339e-05 - val_accuracy: 0.5003\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 7.9314e-05 - accuracy: 0.5004 - val_loss: 1.6265e-05 - val_accuracy: 0.5003\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 2.5549e-05 - accuracy: 0.5004 - val_loss: 1.6021e-05 - val_accuracy: 0.5003\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 2.7863e-05 - accuracy: 0.5004 - val_loss: 1.4990e-05 - val_accuracy: 0.5003\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 4.6864e-05 - accuracy: 0.5004 - val_loss: 2.3311e-05 - val_accuracy: 0.5003\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 3.7620e-05 - accuracy: 0.5004 - val_loss: 1.4569e-05 - val_accuracy: 0.5003\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 3.2834e-05 - accuracy: 0.5004 - val_loss: 2.2415e-05 - val_accuracy: 0.5003\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 2.2526e-05 - accuracy: 0.5005 - val_loss: 1.5835e-05 - val_accuracy: 0.5003\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 2.3594e-05 - accuracy: 0.5004 - val_loss: 2.3843e-05 - val_accuracy: 0.5003\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 4.7425e-05 - accuracy: 0.5004 - val_loss: 4.9811e-05 - val_accuracy: 0.5003\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 9.7764e-05 - accuracy: 0.5005 - val_loss: 1.3775e-05 - val_accuracy: 0.5003\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 4.0916e-05 - accuracy: 0.5004 - val_loss: 1.1807e-05 - val_accuracy: 0.5003\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 2.9912e-05 - accuracy: 0.5004 - val_loss: 2.4647e-05 - val_accuracy: 0.5003\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 4.4975e-05 - accuracy: 0.5004 - val_loss: 2.1004e-05 - val_accuracy: 0.5003\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_input, Y_output_flattened, \n",
    "          epochs=100, \n",
    "          batch_size=256,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[tensorboard_callback]\n",
    "          )\n",
    "model.save(\"C4_combine.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
